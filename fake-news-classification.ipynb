{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignore warning messages\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\n# Handle table-like data and matrices\nimport numpy as np\nimport pandas as pd\n\n# Computations\nimport itertools\n\n# Modelling Algorithms\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import PassiveAggressiveClassifier\n\n# Modelling Helpers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import metrics\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\n# Visualization\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ## Load Data "},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/fake-news/train.csv\")\ntest  = pd.read_csv (\"/kaggle/input/fake-news/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train Shape : {train.shape}\")\nprint(f\"Test Shape : {test.shape}\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handeling missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# not removing the missing values; as studied in the prior kernal 13% data is missing, removing that from training will cause 13% diversified learning to the model. So filling the missing data with empty string."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Handle missing values\ntest=test.fillna(' ')\ntrain=train.fillna(' ')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We will train the model with concatenating of the title, the author and the main text, the model would be more generalized because adding more words to the input might increase the reliablity of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a column with all the data available\ntest['total']=test['title']+' '+test['author']+' '+test['text']\ntrain['total']=train['title']+' '+train['author']+' '+train['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Have a glance at our training set\ntrain.info()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividing the training set by using train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train['total'], train.label, test_size=0.20, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorizing Data"},{"metadata":{},"cell_type":"markdown","source":"### 1. Count Vectorizer "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the `count_vectorizer` \ncount_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english') \n# Fit and transform the training data.\ncount_train = count_vectorizer.fit_transform(X_train)\n# Transform the test set \ncount_test = count_vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_counts_vector = count_vectorizer.transform(test['total'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Tf-IDF Vectorizer "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize the `tfidf_vectorizer` \ntfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n#Fit and transform the training data \ntfidf_train = tfidf_vectorizer.fit_transform(X_train)\n#Transform the test set \ntfidf_test = tfidf_vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tfidf_vector = tfidf_vectorizer.transform(test['total'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Playing with the algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a function that outputs a confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def precision_recall(true_label, predicted_label):\n    precision = precision_score(true_label, predicted_label)\n    print('Precision: %f' % precision)\n\n    recall = recall_score(true_label, predicted_label)\n    print('Recall: %f' % recall)\n    \n    accuracy = metrics.accuracy_score(true_label, predicted_label)\n    print('Accuracy: %f' % accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Multinomial Naive Bayes with Count Vectorizer (BagofWords)"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_classifier = MultinomialNB(alpha = 0.1)\nnb_classifier.fit(count_train, y_train)\npred_nb_count = nb_classifier.predict(count_test)\nprecision_recall(y_test, pred_nb_count)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tune the hyperparameter alpha for the naive bayes classifier\nfor alpha in np.arange(0,1,.05):\n    nb_classifier_tune = MultinomialNB(alpha=alpha)\n    nb_classifier_tune.fit(count_train, y_train)\n    pred_tune = nb_classifier_tune.predict(count_test)\n    precision_recall(y_test, pred_tune)\n    print(\"Alpha: {:.2f} \".format(alpha))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best score is obtained for alpha = 0.15, and is equal to 0.94279."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's re-run our fine-tuned model and plot the confusion matrix\nnb_classifier = MultinomialNB(alpha = 0.15)\nnb_classifier.fit(count_train, y_train)\npred_nb_count = nb_classifier.predict(count_test)\nprecision_recall(y_test, pred_nb_count)\ncm = metrics.confusion_matrix(y_test, pred_nb_count, labels=[0,1])\n    \n    \nplot_confusion_matrix(cm, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Count Vectorizer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that although our model has a general accuracy of 94.3 %, which is good, but it does not really score well in view of number of false negative. 223 fake news are classified as true news with this model, which is not pleasing to see. So we will try to use the Tf-IDF vectorizer on this same model to see if it performs better."},{"metadata":{},"cell_type":"markdown","source":"### 2. Multinomial Naive Bayes with TF-IDF Vectorizer "},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_classifier = MultinomialNB(alpha = 0.1)\nnb_classifier.fit(tfidf_train, y_train)\npred_nb_tfidf = nb_classifier.predict(tfidf_test)\nprecision_recall(y_test, pred_nb_tfidf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tune the hyperparameter alpha for the naive bayes classifier\nfor alpha in np.arange(0,0.1,.01):\n    nb_classifier_tune = MultinomialNB(alpha=alpha)\n    nb_classifier_tune.fit(tfidf_train, y_train)\n    pred_tune = nb_classifier_tune.predict(tfidf_test)\n    precision_recall(y_test, pred_tune)\n    print(\"Alpha: {:.2f} \".format(alpha))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's run the optimized model with best value of hyperparameter and check the confusion matrix\nnb_classifier = MultinomialNB(alpha = 0.01)\nnb_classifier.fit(tfidf_train, y_train)\npred_nb_tfidf = nb_classifier.predict(tfidf_test)\nprecision_recall(y_test, pred_nb_tfidf)\ncm2 = metrics.confusion_matrix(y_test, pred_nb_tfidf, labels=[0,1])\nplot_confusion_matrix(cm2, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Tf-IDF')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This confusion matrix above confirms that this new model is slightly better (and its accuracy score is 94.4 %).\nHowever, too many fake news are still labeled as true news.\nLet's try with another model called PassiveAgressive Classifier which is special for text classification purposes. "},{"metadata":{},"cell_type":"markdown","source":"### 3. Passive Agressive Classifier With Count Vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import PassiveAggressiveClassifier\nlinear_classifier = PassiveAggressiveClassifier(max_iter=10)\nlinear_classifier.fit(count_train, y_train)\npred_linear_count = linear_classifier.predict(count_test)\nprecision_recall(y_test, pred_linear_count)\ncm6 = metrics.confusion_matrix(y_test, pred_linear_count, labels=[0,1])\nplot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a PA Classifier with Count Vectorizer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get much better results than with the MultinomialNB model, both in terms of accuracy and in terms of false negative. Only 60 fake news were labeled as true news this time.\nLet's try with the Tf-IDF method."},{"metadata":{},"cell_type":"markdown","source":"### 4. Passive Agressive Classifier With TF-IDF Vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_classifier = PassiveAggressiveClassifier(max_iter=10)\nlinear_classifier.fit(tfidf_train, y_train)\npred_linear_tfidf = linear_classifier.predict(tfidf_test)\nprecision_recall(y_test, pred_linear_tfidf)\n\ncm5 = metrics.confusion_matrix(y_test, pred_linear_tfidf, labels=[0,1])\nplot_confusion_matrix(cm5, classes=['TRUE','FAKE'], title ='Confusion matrix for a PA Classifier with Tf-IDF')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although we observe more false negative, the overall accuracy is much better, hence so far this is our best model.\nLet's try with Logistic Regression now !"},{"metadata":{},"cell_type":"markdown","source":"### 5. Logistic Regression with TF-IDF Vectorizer "},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(C=1e5)\nlogreg.fit(tfidf_train, y_train)\npred_logreg_tfidf = logreg.predict(tfidf_test)\npred_logreg_tfidf_proba = logreg.predict_proba(tfidf_test)[:,1]\nprecision_recall(y_test, pred_logreg_tfidf)\n\ncm4 = metrics.confusion_matrix(y_test, pred_logreg_tfidf, labels=[0,1])\nplot_confusion_matrix(cm4, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Tf-IDF')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = logreg.predict(test_tfidf_vector)\npred=pd.DataFrame(predictions,columns=['label'])\npred['id']=test['id']\npred.groupby('label').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.to_csv('tfidf_pred.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model has a very high accuracy score, and only 58 records were misclassified. So far, Logistic Regression played it best ! Let's see the same with CountVectorizer ie. Bag of Words concept."},{"metadata":{},"cell_type":"markdown","source":"### 6.  Logistic Regression with CountVectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(C=1e5)\nlogreg.fit(count_train, y_train)\npred_logreg_count = logreg.predict(count_test)\nprecision_recall(y_test, pred_logreg_count)\n\ncm3 = metrics.confusion_matrix(y_test, pred_logreg_count, labels=[0,1])\nplot_confusion_matrix(cm3, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Count Vectorizer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions1 = logreg.predict(test_counts_vector)\npred1 = pd.DataFrame(predictions1, columns=['label'])\npred1['id'] = test['id']\npred1.groupby('label').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.to_csv('countvect_pred.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# It's THE BEST MODEL. Even though the accuracy score is a bit lower, we have less fake news labeled as true news ie. only 44. Therefore, I choose this model because it seems to maximize the accuracy while minimizing the false negative rate!"},{"metadata":{},"cell_type":"markdown","source":"# The accuracy according to the kaggle submission on the Test set is 97.82%"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}